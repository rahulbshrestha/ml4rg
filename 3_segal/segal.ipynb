{
 "cells": [
  {
   "cell_type": "code",
   "id": "bef361bf-7532-4329-a27f-2234d6218c8f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, TrainingArguments,Trainer\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, IA3Config, get_peft_model\n",
    "\n",
    "from utils import *\n",
    "from models import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "363cf292-95f3-4cb0-bdbf-146539601fbf",
   "metadata": {},
   "source": [
    "## Setting random state for results reproducability"
   ]
  },
  {
   "cell_type": "code",
   "id": "078eb193-d9cd-4043-8e7a-ce3d75c02b1b",
   "metadata": {},
   "source": [
    "# Set the seed for Python's built-in random module\n",
    "random.seed(42)\n",
    "\n",
    "# Set the seed for NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the seed for PyTorch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the seed for PyTorch CUDA (if using GPU)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)  # if you are using multi-GPU\n",
    "\n",
    "# Ensure deterministic behavior for certain operations\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58876b7c-9026-4d3a-8168-5c7574c8ce94",
   "metadata": {},
   "source": [
    "# SpeciesLM"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d70d70e-bb37-405c-a75e-7b0c98c0778b",
   "metadata": {},
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gagneurlab/SpeciesLM\", revision=\"downstream_species_lm\")\n",
    "lm = AutoModelForMaskedLM.from_pretrained(\"gagneurlab/SpeciesLM\", revision=\"downstream_species_lm\")\n",
    "\n",
    "lm.eval()\n",
    "device = \"cuda\"\n",
    "lm.to(device)\n",
    "print(\"Done\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f7fd699c-a482-400e-912e-39781b906bb4",
   "metadata": {},
   "source": [
    "# Loading and Tokenizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "39de0ff4-af36-4269-b93c-ef5d74884998",
   "metadata": {},
   "source": [
    "mpra_df = pd.read_csv(\"./data/segal_2015.tsv\",sep=\"\\t\").dropna().reset_index(drop=True).reset_index()\n",
    "\n",
    "mpra_df[\"text\"] = [\"candida_glabrata \" + \" \".join(get_kmers(seq)) for seq in mpra_df[\"Oligo Sequence\"]]\n",
    "mpra_df[\"label\"] = np.log2(mpra_df[\"Expression\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44df1b20-7602-4f80-a5ed-2f1147067dcb",
   "metadata": {},
   "source": [
    "df = mpra_df[[\"text\", \"label\"]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58342b7d-c675-4da4-bb6a-9101fa904389",
   "metadata": {},
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3fbeccc2-1ea3-41c1-a069-628110c5afb3",
   "metadata": {},
   "source": [
    "train_df, test_val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_df, val_df = train_test_split(test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e123a0ef-479f-41a6-8cc9-54863bed3c2a",
   "metadata": {},
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "# Tokenize the data\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d7ddc56-ff15-40f9-ab8f-0cb254bc3865",
   "metadata": {},
   "source": [
    "train_dataset = train_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\", \"__index_level_0__\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97fc1448-a2a2-4aa2-89cc-fcbb5b933829",
   "metadata": {},
   "source": [
    "train_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4f38a18-6e75-4d4a-a2bd-0659d5d1b01f",
   "metadata": {},
   "source": [
    "test_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0862f30a-5987-4771-a671-0b49dd7f2cfb",
   "metadata": {},
   "source": [
    "val_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd7253c6-6bd0-4710-a757-1150387a31ba",
   "metadata": {},
   "source": [
    "# Training and Testing the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "b800b41f-2c81-468c-a70e-ae6a1b008e9b",
   "metadata": {},
   "source": [
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b922f4a6-c2d9-4794-ad51-341e3d888e9a",
   "metadata": {},
   "source": [
    "# An ugly code block to select the fine tuning method to use for dora and lora\n",
    "# if should be set to true and use_dora should also be set to necessary value\n",
    "# for baseline if should be set to False and elif should be set to True\n",
    "# for IA3 if and elif should be set to False\n",
    "\n",
    "lr = 1e-4 # base: 2e-3\n",
    "batch_size = 16 # base: 32\n",
    "\n",
    "\n",
    "if True:\n",
    "    # dora or lora\n",
    "    rank = 32 #2, 4, 8, 16, 32\n",
    "    use_dora = True\n",
    "    if use_dora:\n",
    "        method = \"DoRA\"\n",
    "    else:\n",
    "        method = \"LoRA\"\n",
    "        \n",
    "    config = LoraConfig(\n",
    "        use_dora=use_dora,\n",
    "        r=rank,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.01,\n",
    "        bias=\"none\",\n",
    "    )\n",
    "    lm = get_peft_model(lm, config)\n",
    "elif False:\n",
    "    # baseline\n",
    "    method = \"baseline\"\n",
    "    rank = 0\n",
    "    use_dora = False\n",
    "else:\n",
    "    # IA3\n",
    "    method = \"IA3\"\n",
    "    rank = 0\n",
    "    use_dora = \"IA3\"\n",
    "    config = IA3Config(\n",
    "    peft_type=\"IA3\",\n",
    "    )\n",
    "    lm = get_peft_model(lm, config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b499ad32-ae8d-4b9a-bb72-1f379267c95b",
   "metadata": {},
   "source": [
    "model = EncoderForRegression(lm).to(device)\n",
    "print_trainable_parameters(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae5d12ff-87ae-4743-ad5b-fca2b72a7e27",
   "metadata": {},
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"epoch\", \n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8002cd9a-dd06-40c6-a3bb-b4649fb2d30d",
   "metadata": {},
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "training_perform = trainer.evaluate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "835de129-67f7-4774-8a4a-d52168caf8e9",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d036a92-da1c-4743-a478-b34461d2e5b2",
   "metadata": {},
   "source": [
    "# Make prediction\n",
    "test_result = trainer.predict(val_dataset) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d65aa375-c6ac-4635-ba63-55f412d202b9",
   "metadata": {},
   "source": [
    "predictions = test_result.predictions\n",
    "labels = test_result.label_ids\n",
    "metrics = test_result.metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9577e1b-0708-4767-b8be-0aecdee4b92b",
   "metadata": {},
   "source": [
    "metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd673802-ac11-4de2-9d34-cabd2d8d7a91",
   "metadata": {},
   "source": [
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(labels, predictions.flatten())\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Mean Squared Error\n",
    "mse = mean_squared_error(labels, predictions.flatten())\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# R-squared Score\n",
    "r2 = r2_score(labels, predictions.flatten())\n",
    "print(f\"R-squared (R2) Score: {r2}\")\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "mape = np.mean(np.abs((labels - predictions.flatten()) / labels)) * 100\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "565b43b6-c236-4d7f-b78b-0587dc0075b0",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "id": "81dfe132-37cc-4136-83d3-1c1e9938cfe4",
   "metadata": {},
   "source": [
    "# Define the path to your CSV file\n",
    "csv_file_path = './data/final_results.csv'\n",
    "\n",
    "# Function to load existing DataFrame or create a new one if it doesn't exist\n",
    "def load_dataframe(csv_file_path):\n",
    "    if os.path.exists(csv_file_path):\n",
    "        return pd.read_csv(csv_file_path)\n",
    "    else:\n",
    "        # Create an empty DataFrame with the required columns\n",
    "        columns = ['method', 'use_Dora','rank','batch_size','learning_rate','MAE', 'MSE', 'RMSE', 'R2','pearson', 'MAPE', 'Trainable Params', 'All Params', 'Trainable Percentage', 'Runtime']\n",
    "        return pd.DataFrame(columns=columns)\n",
    "df = load_dataframe(csv_file_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a28a9594-7a37-4f77-a782-318e87bee59c",
   "metadata": {},
   "source": [
    "trainable_params = 0\n",
    "all_param = 0\n",
    "for _, param in model.named_parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "print(\n",
    "    f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5445baa-000f-417d-bcac-ec5af0eb7655",
   "metadata": {},
   "source": [
    "data = pd.DataFrame([{\n",
    "    'method' : method,\n",
    "    'use_Dora' : use_dora,\n",
    "    'rank' : rank,\n",
    "    'batch_size' : batch_size,\n",
    "    'learning_rate' : lr,\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'R2': r2,\n",
    "    'pearson': pearson_r2_metric(labels, predictions.flatten()),\n",
    "    'MAPE': mape,\n",
    "    'Trainable Params': trainable_params,\n",
    "    'All Params': all_param,\n",
    "    'Trainable Percentage': 100 * trainable_params / all_param,\n",
    "    'Runtime': training_perform['eval_runtime']\n",
    "}])\n",
    "\n",
    "df = pd.concat([df, data], ignore_index=True)\n",
    "\n",
    "# Save DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "23287b83-bff4-4d50-a2be-d78fbc099a15",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "id": "fccab674-bc84-495b-91b8-4ef81ede55b7",
   "metadata": {},
   "source": [
    "# # Make prediction\n",
    "# test_result = trainer.predict(test_dataset) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15b07d1a-f958-4850-8c25-23b34305b19a",
   "metadata": {},
   "source": [
    "# predictions = test_result.predictions\n",
    "# labels = test_result.label_ids\n",
    "# metrics = test_result.metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "641e3f5c-ca3c-4bae-a551-1667f71e8230",
   "metadata": {},
   "source": [
    "# metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0326d363-639c-4673-bb2f-099811e524c2",
   "metadata": {},
   "source": [
    "# # Mean Absolute Error\n",
    "# mae = mean_absolute_error(labels, predictions.flatten())\n",
    "# print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# # Mean Squared Error\n",
    "# mse = mean_squared_error(labels, predictions.flatten())\n",
    "# print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# # Root Mean Squared Error\n",
    "# rmse = np.sqrt(mse)\n",
    "# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# # R-squared Score\n",
    "# r2 = r2_score(labels, predictions.flatten())\n",
    "# print(f\"R-squared (R2) Score: {r2}\")\n",
    "\n",
    "# # Mean Absolute Percentage Error\n",
    "# mape = np.mean(np.abs((labels - predictions.flatten()) / labels)) * 100\n",
    "# print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "de425394-6f6d-44ef-abfb-a91ae6c9975c",
   "metadata": {},
   "source": [
    "# # Define the path to your CSV file\n",
    "# csv_file_path = './data/final_results.csv'\n",
    "\n",
    "# # Function to load existing DataFrame or create a new one if it doesn't exist\n",
    "# def load_dataframe(csv_file_path):\n",
    "#     if os.path.exists(csv_file_path):\n",
    "#         return pd.read_csv(csv_file_path)\n",
    "#     else:\n",
    "#         # Create an empty DataFrame with the required columns\n",
    "#         columns = ['method', 'use_Dora','rank','batch_size','learning_rate','MAE', 'MSE', 'RMSE', 'R2','pearson', 'MAPE', 'Trainable Params', 'All Params', 'Trainable Percentage', 'Runtime']\n",
    "#         return pd.DataFrame(columns=columns)\n",
    "# df = load_dataframe(csv_file_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "daa179d9-b74b-49a3-bb8b-d5c8716fe37a",
   "metadata": {},
   "source": [
    "# trainable_params = 0\n",
    "# all_param = 0\n",
    "# for _, param in model.named_parameters():\n",
    "#     all_param += param.numel()\n",
    "#     if param.requires_grad:\n",
    "#         trainable_params += param.numel()\n",
    "# print(\n",
    "#     f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7b6f97a-32b4-4ae1-8b09-32f8a8921299",
   "metadata": {},
   "source": [
    "# data = pd.DataFrame([{\n",
    "#     'method' : method + '_test',\n",
    "#     'use_Dora' : use_dora,\n",
    "#     'rank' : rank,\n",
    "#     'batch_size' : batch_size,\n",
    "#     'learning_rate' : lr,\n",
    "#     'MAE': mae,\n",
    "#     'MSE': mse,\n",
    "#     'RMSE': rmse,\n",
    "#     'R2': r2,\n",
    "#     'pearson': pearson_r2_metric(labels, predictions.flatten()),\n",
    "#     'MAPE': mape,\n",
    "#     'Trainable Params': trainable_params,\n",
    "#     'All Params': all_param,\n",
    "#     'Trainable Percentage': 100 * trainable_params / all_param,\n",
    "#     'Runtime': training_perform['eval_runtime']\n",
    "# }])\n",
    "\n",
    "# df = pd.concat([df, data], ignore_index=True)\n",
    "\n",
    "# # Save DataFrame to the CSV file\n",
    "# df.to_csv(csv_file_path, index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ad6e941-fd70-493a-9ca4-4990277d6295",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-l_yurt]",
   "language": "python",
   "name": "conda-env-.conda-l_yurt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
